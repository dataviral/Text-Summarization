{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATH VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/news_summary.csv\"\n",
    "MODEL_PATH = \"./model_checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TUNABLE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_WORDS = 25000\n",
    "VOCAB_SIZE = NUM_WORDS + 4\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 10\n",
    "\n",
    "MAX_TEXT_LEN = 300\n",
    "MAX_SUM_LEN = 60\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_TEST = 300\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import get_data\n",
    "from data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the data: 4514\n",
      "Length of the data after dropping nan: 4396\n"
     ]
    }
   ],
   "source": [
    "data, w2i, i2w = get_data(DATA_PATH, NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = Dataset(data[:-5], w2i, MAX_TEXT_LEN, MAX_SUM_LEN, isTrain=True)\n",
    "dataset_test = Dataset(data[5:], w2i, MAX_TEXT_LEN, MAX_SUM_LEN, isTrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Collate functions\n",
    "def collate_fn_train(data):\n",
    "    text, summary = zip(*data)\n",
    "\n",
    "    text_lens = [len(i) for i in text]\n",
    "    summary_lens = [len(i) for i in summary]\n",
    "\n",
    "    text = torch.nn.utils.rnn.pad_sequence(text, batch_first=True, padding_value=w2i['<pad>'])\n",
    "    summary = torch.nn.utils.rnn.pad_sequence(summary, batch_first=True, padding_value=w2i['<pad>'])\n",
    "\n",
    "    text_lens = torch.from_numpy(np.asarray(text_lens))\n",
    "    summary_lens = torch.from_numpy(np.asarray(summary_lens))\n",
    "\n",
    "    return (text, text_lens), (summary, summary_lens)\n",
    "\n",
    "\n",
    "def collate_fn_test(texts):\n",
    "    text_lens = [len(i) for i in texts]\n",
    "    texts = torch.nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=w2i['<pad>'])\n",
    "\n",
    "    text_lens = torch.from_numpy(np.asarray(text_lens))\n",
    "    return texts, text_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, BATCH_SIZE, num_workers=4, shuffle=True, collate_fn=collate_fn_train)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, BATCH_SIZE // 4, num_workers=4, shuffle=False, collate_fn=collate_fn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INIT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (embedding): Embedding(\n",
       "    (embedding): Embedding(25004, 100)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (encoder_network): LSTM(100, 10, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder_network): LSTM(100, 10, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (project): Projection(\n",
       "    (projection_layer): Linear(in_features=20, out_features=25004, bias=True)\n",
       "  )\n",
       "  (attention): Attention()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, n_epochs, train_loader, valid_loader):\n",
    "    teacher_force = 0.3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "    criterion = nn.NLLLoss(reduction='none')\n",
    "    for ep in range(n_epochs):\n",
    "        train_batch(model, ep + 1, train_loader, optimizer, teacher_force, criterion)\n",
    "        torch.cuda.empty_cache()\n",
    "        valid_batch(model, valid_loader, criterion)\n",
    "\n",
    "        # Save model every 10 epochs\n",
    "        if (ep + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), MODEL_PATH + \"m1_e{}.model\".format(ep))\n",
    "        \n",
    "        # Reduce LR every 40 epochs\n",
    "        if (ep + 1) % 10 == 0:\n",
    "            for p in optimizer.param_groups:\n",
    "                p['lr'] *= 0.5\n",
    "        \n",
    "        # Reduce teacher forcing by 10% every 20 epochs\n",
    "        if (ep + 1) % 10 == 0:\n",
    "            if teacher_force >= 50:\n",
    "                teacher_force -= 0.1\n",
    "\n",
    "\n",
    "def train_batch(model, n_epoch, dataloader, optimizer, teacher_force, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch_num, ((x, xlens), (y, ylens)) in enumerate(dataloader):\n",
    "\n",
    "        # setup tensors\n",
    "        x = x.long().to(DEVICE)\n",
    "        y = y.long().to(DEVICE)\n",
    "\n",
    "        # clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # generate predictions\n",
    "        # output: (BATCH_SIZE, time_steps, NUM_WORDS)\n",
    "        output = model(x, xlens, y, teacher_force_prob=teacher_force)\n",
    "\n",
    "        ### Calculate Loss\n",
    "        # 1. y must be shifted by 1 for loss calc. since outputs should not not contain <sos>\n",
    "        y_true = torch.cat([y[:, 1:], torch.ones((y.size(0), 1)).long().to(DEVICE) * w2i[\"<pad>\"]], dim=-1)\n",
    "        # 2. Ouput shape for loss calculation must be of the form (BATCH_SIZE, NUM_WORDS, *)\n",
    "        # Refer pytorch docs for more details\n",
    "        loss = criterion(output.permute(0, 2, 1), y_true)\n",
    "\n",
    "        # 3. Mask the loss. Needed since we have padding which is not needed\n",
    "        # Can avoid if using pack_padded sequence?\n",
    "        num_tokens = 0\n",
    "        for i, yl in enumerate(ylens):\n",
    "            loss[i, yl-1:] *= 0 # yl-1 to remove <sos>\n",
    "            num_tokens += yl - 1\n",
    "\n",
    "        # 4. SUM the losses then divide by number of tokens and finally call backward\n",
    "        loss = loss.sum() / num_tokens\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "\n",
    "        # Adjust parameters\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Display training stats\n",
    "    print(\"EP: {} Loss: {}\".format(n_epoch, total_loss / len(dataloader)))\n",
    "\n",
    "\n",
    "def valid_batch(model, dataloader, criterion):\n",
    "    total_loss = 0.\n",
    "    model.eval()\n",
    "    for batch_num, ((x, xlens), (y, ylens)) in enumerate(dataloader):\n",
    "\n",
    "        # setup tensors\n",
    "        x = x.long().to(DEVICE)\n",
    "        y = y.long().to(DEVICE)\n",
    "\n",
    "        # generate predictions\n",
    "        # output: (BATCH_SIZE, time_steps, NUM_WORDS)\n",
    "        output = model(x, xlens, y, teacher_force_prob=0)\n",
    "\n",
    "        ### Calculate Loss\n",
    "        # 1. y must be shifted by 1 for loss calc. since outputs should not not contain <sos>\n",
    "        y_true = torch.cat([y[:, 1:], torch.ones((y.size(0), 1)).long().to(DEVICE) * w2i[\"<pad>\"]], dim=-1)\n",
    "        # 2. Ouput shape for loss calculation must be of the form (BATCH_SIZE, NUM_WORDS, *)\n",
    "        # Refer pytorch docs for more details\n",
    "        loss = criterion(output.permute(0, 2, 1), y_true)\n",
    "\n",
    "        # 3. Mask the loss. Needed since we have padding which is not needed\n",
    "        # Can avoid if using pack_padded sequence?\n",
    "        num_tokens = 0\n",
    "        for i, yl in enumerate(ylens):\n",
    "            loss[i, yl-1:] *= 0 # yl-1 to remove <sos>\n",
    "            num_tokens += yl - 1\n",
    "\n",
    "        # 4. SUM the losses then divide by number of tokens and finally call backward\n",
    "        loss = loss.sum() / num_tokens\n",
    "\n",
    "        #Add loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Display test stats\n",
    "    print(\"Test Loss: {}\".format(total_loss / len(dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 1 Loss: 10.102949142456055\n",
      "Test Loss: 10.096566772460937\n",
      "EP: 2 Loss: 10.093341827392578\n",
      "Test Loss: 10.091037178039551\n",
      "EP: 3 Loss: 10.065802574157715\n",
      "Test Loss: 10.085530471801757\n",
      "EP: 4 Loss: 10.06158447265625\n",
      "Test Loss: 10.079562187194824\n",
      "EP: 5 Loss: 10.056870937347412\n",
      "Test Loss: 10.073042488098144\n",
      "EP: 6 Loss: 10.04487943649292\n",
      "Test Loss: 10.065895462036133\n",
      "EP: 7 Loss: 10.025747776031494\n",
      "Test Loss: 10.059509086608887\n",
      "EP: 8 Loss: 10.010315895080566\n",
      "Test Loss: 10.053603363037109\n",
      "EP: 9 Loss: 9.99931287765503\n",
      "Test Loss: 10.047212600708008\n",
      "EP: 10 Loss: 9.999106407165527\n",
      "Test Loss: 10.042146492004395\n",
      "EP: 11 Loss: 9.98165512084961\n",
      "Test Loss: 10.0408145904541\n",
      "EP: 12 Loss: 9.98488712310791\n",
      "Test Loss: 10.037449836730957\n",
      "EP: 13 Loss: 9.961812496185303\n",
      "Test Loss: 10.033622741699219\n",
      "EP: 14 Loss: 9.952765941619873\n",
      "Test Loss: 10.030361938476563\n",
      "EP: 15 Loss: 9.945680141448975\n",
      "Test Loss: 10.026434898376465\n",
      "EP: 16 Loss: 9.952454090118408\n",
      "Test Loss: 10.02233829498291\n",
      "EP: 17 Loss: 9.944035530090332\n",
      "Test Loss: 10.018043518066406\n",
      "EP: 18 Loss: 9.934622764587402\n",
      "Test Loss: 10.01409854888916\n",
      "EP: 19 Loss: 9.913211345672607\n",
      "Test Loss: 10.009265518188476\n",
      "EP: 20 Loss: 9.901822566986084\n",
      "Test Loss: 10.003000831604004\n",
      "EP: 21 Loss: 9.883728981018066\n",
      "Test Loss: 10.0008056640625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-561141d0848e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-2123b08d2af1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvalid_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-2123b08d2af1>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(model, n_epoch, dataloader, optimizer, teacher_force, criterion)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# setup tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, 200, dataloader_train, dataloader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model, dataloader):\n",
    "    model.eval()\n",
    "    for (x, xlens), (y, ylens) in enumerate(dataloader):\n",
    "        raise NotImplemented(\"TODO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [FNC]",
   "language": "python",
   "name": "Python [FNC]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
